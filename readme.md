# 基于 C 语言与本地 LLM 的智能终端助手 - 答辩报告

项目报告由Gemini生成。

## 1. 项目简介
本项目是一个运行在终端的智能助手，它将 **C 语言的高效系统编程能力** 与 **LLM（大语言模型）的自然语言理解能力** 深度融合。用户无需记忆复杂的命令行指令，只需使用自然语言（如“提醒我买菜”、“记个电话”），即可完成待办管理、备忘录记录、联系人管理等操作。

## 2. 核心架构与设计
项目采用模块化设计，主要包含以下层级：
* **交互层 (`src/chatbot.c`)**：负责用户输入的主循环与鉴权，充当“中控台”角色，将解析后的意图分发给具体模块。
* **智能层 (`src/llm.c`)**：通过 Prompt Engineering 将非结构化的自然语言转化为结构化的 `Intent`（意图）和 `Parameter`（参数）。
* **网络层 (`src/http.c`)**：纯手写的 HTTP/1.1 客户端，直接基于 Socket API 实现，零第三方依赖。
* **功能层**：包含待办 (`todo`)、备忘 (`memo`)、联系人 (`contact`) 等业务模块。

## 3. 技术亮点与优势

### 3.1 纯手写底层网络协议栈
为了追求极致的轻量化和可控性，项目没有引入 `libcurl` 等庞大的网络库，而是手动实现了底层通信：
* **Socket 编程**：完整处理了 Windows (`winsock2`) 和 Linux 的跨平台兼容性。
* **HTTP 协议构造**：手动拼接 `POST` 请求头，精确计算 `Content-Length`，处理 TCP 粘包问题。
* **手写 JSON 解析器**：编写了高效的字符串搜索算法 `http_extract_json_string`，在不引入 `cJSON` 的情况下实现了对 AI 响应数据的精准提取。

### 3.2 鲁棒的混合意图识别
针对本地小参数模型（如 Qwen-1.5B）输出格式不稳定的痛点，采取了“AI + 规则”的双重保障策略：
* **Prompt 约束**：在系统提示词中严格规定输出格式为 `类别|参数`，并给出包含“错误示范”的 Few-Shot 示例。
* **代码级容错**：在 C 代码中实现了模糊匹配算法。即使 AI 输出了多余的表头或前缀（如“参数：”），程序也能自动清洗数据，提取核心内容，极大地提高了系统的稳定性。

### 3.3 多样化的数据结构实践
项目中应用了多种 C 语言经典数据结构，体现了扎实的编程基础：
* **动态链表**：在 `contact` 模块中使用链表管理联系人，支持动态内存分配 (`malloc`/`free`)，无数量限制。
* **文件持久化**：在 `memo` 模块中实现了文件的读写操作，保证数据持久存储。
* **内存数组**：在 `todo` 模块中使用静态数组，演示了高效的内存管理。

## 4. 功能演示
1.  **自然语言任务管理**：输入“帮我记下明天交作业”，系统自动识别为 `TODO_ADD` 并存入待办列表。
2.  **智能信息提取**：输入“存一下丁真的电话”，系统自动提取人名“丁真”并调用联系人模块进行交互式录入。
3.  **情感陪伴**：当用户输入无关指令（如“我心情不好”）时，系统自动切换为聊天模式，提供情感支持。

## 5. 总结
本项目成功构建了一个“麻雀虽小，五脏俱全”的 AI Agent 原型。它证明了 C 语言不仅能做底层开发，通过结合 LLM，也能构建出体验优秀的现代智能化应用。项目中对底层协议的手动实现和对数据结构的灵活运用，充分体现了开发者对计算机系统原理的深刻理解。